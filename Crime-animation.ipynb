{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "140827ad",
   "metadata": {},
   "source": [
    "Data Cleaning and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730c8f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef5d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset in csv format into pandas dataframe\n",
    "df = pd.read_csv(\"database/final_crime_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ebcd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d599c11",
   "metadata": {},
   "source": [
    "Print the first five rows of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ec6251",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03046563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df1 = pd.read_csv('Database/final/crime_data_modified_final.csv')\n",
    "\n",
    "# Load the second file\n",
    "df2 = pd.read_csv('Database/final/crime_data_modified_2018_removed_final.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Append df2 to df1\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe back to a new CSV file or overwrite one of the originals\n",
    "combined_df.to_csv('Database/final/combined_file.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc3a0cf",
   "metadata": {},
   "source": [
    "Removing the columns cr_cd_4, cross_street, cr_cd_3, cr_cd_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ebf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('Database/final/crime_data_modified_2018_removed.csv')\n",
    "\n",
    "# Convert 'date_occ' to datetime format if it's not already\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'], errors='coerce')\n",
    "\n",
    "# Extract the year and create a new column 'year_occ'\n",
    "df['year_occ'] = df['date_occ'].dt.year\n",
    "\n",
    "# Save the modified dataframe back to a csv file if needed\n",
    "df.to_csv('Database/final/crime_data_modified_2018_removed_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a2bba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming df is your DataFrame and it's already loaded with your data\n",
    "df = pd.read_csv('Database/final/crime_data_modified.csv')  # Replace 'your_dataset.csv' with your actual file path\n",
    "\n",
    "# Filter the DataFrame to include only rows where 'year_rept' is 2018 or 2019\n",
    "filtered_df = df[df['year_rept'].isin([2018, 2019])]\n",
    "\n",
    "# Now filtered_df contains only the rows from the years 2018 and 2019\n",
    "filtered_df.to_csv('Database/final/crime_data_modified1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538d33e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('crime_data_modified_2018.csv')\n",
    "# Removing rows where the year column is 2016\n",
    "# List of years to be removed\n",
    "years_to_remove = [2010, 2011, 2012, 2013, 2014]\n",
    "\n",
    "# Removing rows where the year column is in the list of years to remove\n",
    "df = df[~df['year_rept'].isin(years_to_remove)]\n",
    "\n",
    "# Display the DataFrame after removal\n",
    "print(\"\\nDataFrame after removing rows for years 2011, 2012, 2013, and 2014:\")\n",
    "print(df)\n",
    "\n",
    "df.to_csv('crime_data_modified_2018_removed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca88a543",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the first file\n",
    "df1 = pd.read_csv('crime_data_modified.csv')\n",
    "\n",
    "# Load the second file\n",
    "df2 = pd.read_csv('crime_data_modified_2018_removed.csv')\n",
    "\n",
    "# Append df2 to df1\n",
    "combined_df = pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "# Save the combined dataframe to a new CSV file\n",
    "combined_df.to_csv('combined_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6a2da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the first file\n",
    "# Load the first file\n",
    "df1 = pd.read_csv('Database/final/crime_data_modified_final.csv')\n",
    "\n",
    "# Load the second file\n",
    "df2 = pd.read_csv('Database/final/crime_data_modified_2018_removed_final.csv')\n",
    "\n",
    "# Filter out rows where latitude or longitude is 0\n",
    "df1 = df1[(df1['lat'] != 0) & (df1['lon'] != 0)]\n",
    "df2 = df2[(df2['lat'] != 0) & (df2['lon'] != 0)]\n",
    "\n",
    "df1.to_csv('Database/final/crime_data_modified_final.csv', index=False)\n",
    "df2.to_csv('Database/final/crime_data_modified_2018_removed_final.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load data from CSV files\n",
    "data_2018_2019 = pd.read_csv('Database/final/crime_data_modified_2018_removed_final.csv')\n",
    "data_2020_2024 = pd.read_csv('Database/final/crime_data_modified_final.csv')\n",
    "\n",
    "# Combine the two dataframes\n",
    "data_combined = pd.concat([data_2018_2019, data_2020_2024], ignore_index=True)\n",
    "\n",
    "# Group the data by year and area, and count the occurrences\n",
    "crime_counts = data_combined.groupby(['year_rept', 'area_name']).size().reset_index(name='count')\n",
    "\n",
    "# Calculate the total crimes per year to use for normalization\n",
    "total_crimes_per_year = crime_counts.groupby('year_rept')['count'].sum()\n",
    "\n",
    "# Merge the total crimes back with the crime counts to calculate normalized rates\n",
    "normalized_crime_rates = crime_counts.merge(total_crimes_per_year, on='year_rept', suffixes=('', '_total'))\n",
    "normalized_crime_rates['normalized_rate'] = normalized_crime_rates['count'] / normalized_crime_rates['count_total']\n",
    "\n",
    "# Pivot data for plotting\n",
    "pivot_table = normalized_crime_rates.pivot(index='area_name', columns='year_rept', values='normalized_rate')\n",
    "\n",
    "# Plotting\n",
    "pivot_table.plot(kind='bar', figsize=(14, 7))\n",
    "plt.title('Normalized Crime Rates by Area and Year')\n",
    "plt.ylabel('Normalized Crime Rate')\n",
    "plt.xlabel('Area Name')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Year')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1077a05d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Load the crime data\n",
    "df = pd.read_csv(\"Database/final/crime_data_modified.csv\")\n",
    "\n",
    "# Filter unique years\n",
    "unique_years = df['year_rept'].unique()\n",
    "\n",
    "# Dropdown widget for selecting years\n",
    "year_dropdown = widgets.Dropdown(\n",
    "    options=unique_years,\n",
    "    value=unique_years[0],\n",
    "    description='Year:'\n",
    ")\n",
    "\n",
    "# Function to update the map based on selected year\n",
    "def update_map(year):\n",
    "    # Filter the data for the selected year\n",
    "    df_selected_year = df[df['year_rept'] == year]\n",
    "\n",
    "    # Calculate the crime frequency per area\n",
    "    crime_frequency = df_selected_year['area_name'].value_counts().reset_index()\n",
    "    crime_frequency.columns = ['area_name', 'crime_freq']\n",
    "\n",
    "    # Calculate mean coordinates for each area\n",
    "    if 'lat' in df_selected_year.columns and 'lon' in df_selected_year.columns:\n",
    "        mean_coords = df_selected_year.groupby('area_name')[['lat', 'lon']].mean().reset_index()\n",
    "        crime_frequency = pd.merge(crime_frequency, mean_coords, on='area_name', how='left')\n",
    "\n",
    "    # Create a map centered on Los Angeles\n",
    "    map_la = folium.Map(location=[34.0522, -118.2437], zoom_start=10, tiles='cartodbpositron')\n",
    "\n",
    "    # Add a bubble/circle for each area\n",
    "    for _, row in crime_frequency.iterrows():\n",
    "        folium.CircleMarker(\n",
    "            location=[row['lat'], row['lon']],\n",
    "            radius=row['crime_freq'] * 0.0006,  # Scale the circles' radius\n",
    "            color='blue',\n",
    "            fill=True,\n",
    "            fill_color='blue',\n",
    "            fill_opacity=0.7,\n",
    "            tooltip=f\"Area: {row['area_name']}, Crime Frequency: {row['crime_freq']}\"\n",
    "        ).add_to(map_la)\n",
    "\n",
    "    # Display the map\n",
    "    display(map_la)\n",
    "\n",
    "# Display the dropdown widget\n",
    "display(year_dropdown)\n",
    "\n",
    "# Display the map for the initial year\n",
    "update_map(year_dropdown.value)\n",
    "\n",
    "# Event handler for dropdown change\n",
    "def on_dropdown_change(change):\n",
    "    if change['type'] == 'change' and change['name'] == 'value':\n",
    "        update_map(change['new'])\n",
    "\n",
    "# Attach the event handler to the dropdown\n",
    "year_dropdown.observe(on_dropdown_change)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ae881b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"Database/final/crime_data_modified.csv\")\n",
    "\n",
    "# Aggregate data to get crime frequency per area, and calculate mean latitude and longitude\n",
    "data_aggregated = data.groupby('area_name').agg({\n",
    "    'lat': 'mean',\n",
    "    'lon': 'mean',\n",
    "    'area_name': 'size'\n",
    "}).rename(columns={'lat': 'avg_lat', 'lon': 'avg_lon', 'area_name': 'crime_count'}).reset_index()\n",
    "\n",
    "# Load GeoJSON using geopandas (for boundaries, might be used in map visualization context)\n",
    "la_geojson = gpd.read_file(\"Geospatial/los-angeles-county.geojson\")\n",
    "\n",
    "# Create the map with crime icons\n",
    "m = folium.Map(location=[34.0522, -118.2437], zoom_start=10)  # Adjusted to center on Los Angeles\n",
    "\n",
    "# Add marker cluster to map\n",
    "marker_cluster = MarkerCluster().add_to(m)\n",
    "\n",
    "# Define a color function\n",
    "def color_producer(count):\n",
    "    if count > data_aggregated['crime_count'].median():\n",
    "        return 'red'\n",
    "    else:\n",
    "        return 'orange'\n",
    "\n",
    "# Adding markers\n",
    "for idx, row in data_aggregated.iterrows():\n",
    "    folium.Marker(\n",
    "        location=[row['avg_lat'], row['avg_lon']],\n",
    "        popup=f\"{row['area_name']} Crime count: {row['crime_count']}\",\n",
    "        icon=folium.Icon(color=color_producer(row['crime_count']), icon='exclamation-sign', prefix='glyphicon')\n",
    "    ).add_to(marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63f7192",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import folium\n",
    "from folium.plugins import MarkerCluster\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv(\"Database/final/crime_data_modified_final.csv\")\n",
    "\n",
    "# Aggregate data for mean positions and crime counts\n",
    "data_aggregated = data.groupby('area_name').agg({\n",
    "    'lat': 'mean',\n",
    "    'lon': 'mean',\n",
    "    'area_name': 'size'\n",
    "}).rename(columns={'lat': 'avg_lat', 'lon': 'avg_lon', 'area_name': 'crime_count'}).reset_index()\n",
    "\n",
    "# Create the map centered on Los Angeles\n",
    "m = folium.Map(location=[34.0522, -118.2437], zoom_start=10)\n",
    "\n",
    "# Function to determine marker color based on crime count\n",
    "def color_producer(count):\n",
    "    if count > data_aggregated['crime_count'].median():\n",
    "        return 'red'\n",
    "    else:\n",
    "        return 'orange'\n",
    "\n",
    "# Adding main markers for average positions\n",
    "for idx, row in data_aggregated.iterrows():\n",
    "    # Main marker for the area average\n",
    "    marker = folium.Marker(\n",
    "        location=[row['avg_lat'], row['avg_lon']],\n",
    "        popup=f\"{row['area_name']} Crime count: {row['crime_count']}\",\n",
    "        icon=folium.Icon(color=color_producer(row['crime_count']), icon='star')\n",
    "    )\n",
    "    marker.add_to(m)\n",
    "\n",
    "    # Nested Marker Cluster for individual crimes within the area\n",
    "    nested_marker_cluster = MarkerCluster().add_to(marker)\n",
    "\n",
    "    # Filter original data for the current area\n",
    "    area_data = data[data['area_name'] == row['area_name']]\n",
    "    for _, crime in area_data.iterrows():\n",
    "        folium.Marker(\n",
    "            location=[crime['lat'], crime['lon']],\n",
    "            icon=folium.Icon(color='blue', icon='record', prefix='glyphicon'),\n",
    "            popup=f\"Crime: {crime['crime_type']}\"\n",
    "        ).add_to(nested_marker_cluster)\n",
    "\n",
    "# Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d70d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "\n",
    "# Load the crime data\n",
    "df = pd.read_csv(\"Database/final/crime_data_modified.csv\")\n",
    "\n",
    "# Convert 'date_rept' to datetime and extract the year\n",
    "df['year_rept'] = pd.to_datetime(df['date_rept']).dt.year\n",
    "\n",
    "# Filter for 'THEFT OF IDENTITY'\n",
    "df_theft = df[df['cr_cd_desc'].str.upper() == 'THEFT OF IDENTITY']\n",
    "\n",
    "# Calculate the crime frequency per area for each year\n",
    "crime_rate = df_theft.groupby(['year_rept', 'area_name']).size().reset_index(name='crime_freq')\n",
    "\n",
    "# Normalize by total crimes per year\n",
    "total_crimes_per_year = df_theft.groupby('year_rept').size().reset_index(name='total_crimes')\n",
    "crime_rate = pd.merge(crime_rate, total_crimes_per_year, on='year_rept')\n",
    "crime_rate['crime_rate'] = crime_rate['crime_freq'] / crime_rate['total_crimes']\n",
    "\n",
    "# Calculate mean coordinates for each area\n",
    "mean_coords = df_theft.groupby('area_name')[['lat', 'lon']].mean().reset_index()\n",
    "crime_rate = pd.merge(crime_rate, mean_coords, on='area_name', how='left')\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter_geo(crime_rate,\n",
    "                     lat='lat',\n",
    "                     lon='lon',\n",
    "                     color=\"crime_rate\",\n",
    "                     size='crime_rate',\n",
    "                     hover_name='area_name',\n",
    "                     hover_data={'year_rept': True, 'crime_rate': True, 'area_name': False},\n",
    "                     animation_frame='year_rept',\n",
    "                     projection='natural earth',\n",
    "                     title='THEFT OF IDENTITY Crime Rate by Area in Los Angeles Over Years',\n",
    "                     template='plotly_dark')\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.show()\n",
    "\n",
    "\n",
    "# Scaling factor for bubble size\n",
    "scale_factor = 1000  # Adjust this value as needed to get the desired bubble size\n",
    "\n",
    "# Plot using Plotly Express\n",
    "fig = px.scatter_geo(crime_rate,\n",
    "                     lat='lat',\n",
    "                     lon='lon',\n",
    "                     color=\"crime_rate\",\n",
    "                     size=crime_rate['crime_rate'] * scale_factor,  # Apply scaling factor here\n",
    "                     hover_name='area_name',\n",
    "                     hover_data={'year_rept': True, 'crime_rate': True, 'area_name': False},\n",
    "                     animation_frame='year_rept',  # Ensure correct column name for animation\n",
    "                     projection='natural earth',\n",
    "                     title='THEFT OF IDENTITY Crime Rate by Area in Los Angeles Over Years',\n",
    "                     template='plotly_dark')\n",
    "\n",
    "fig.update_geos(fitbounds=\"locations\", visible=False)\n",
    "fig.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1195755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data from a CSV file\n",
    "df = pd.read_csv('crime_data_final.csv')\n",
    "\n",
    "# Ensure the date columns are in datetime format\n",
    "df['date_rept'] = pd.to_datetime(df['date_rept'], errors='coerce')\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'], errors='coerce')\n",
    "\n",
    "# Calculate the delay in days between the reporting and the occurrence\n",
    "df['delay_in_days'] = (df['date_rept'] - df['date_occ']).dt.days\n",
    "\n",
    "# Filter out negative or unrealistic delays\n",
    "df = df[df['delay_in_days'] >= 0]\n",
    "\n",
    "# Create a violin plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.violinplot(x='area_name', y='delay_in_days', data=df)\n",
    "plt.xticks(rotation=90)\n",
    "plt.title('Distribution of Delays by Area')\n",
    "plt.xlabel('Area')\n",
    "plt.ylabel('Delay in Days')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a65657b",
   "metadata": {},
   "source": [
    "Sankey Diagram to Show Flow of Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8125fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Database/final/crime_data_modified_final.csv')\n",
    "\n",
    "# Convert date columns to datetime\n",
    "df['date_rept'] = pd.to_datetime(df['date_rept'])\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'])\n",
    "\n",
    "# Prepare the data by categorizing the delay into intervals\n",
    "df['delay_hours'] = ((df['date_rept'] - df['date_occ']).dt.total_seconds() / 3600).astype(int)\n",
    "df['delay_category'] = pd.cut(df['delay_hours'], bins=[0, 6, 12, 24, 48, 72, 168], labels=['0-6', '6-12', '12-24', '24-48', '48-72', '72-168'])\n",
    "\n",
    "# Count occurrences in each category\n",
    "delay_counts = df['delay_category'].value_counts().reset_index()\n",
    "delay_counts.columns = ['delay_category', 'count']\n",
    "\n",
    "# Create the Sankey diagram\n",
    "fig = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=delay_counts['delay_category'],\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=[0, 1, 2, 3, 4],  # indices correspond to labels\n",
    "        target=[1, 2, 3, 4, 5],\n",
    "        value=delay_counts['count']\n",
    "    ))])\n",
    "\n",
    "fig.update_layout(title_text='Flow of Time from Occurrence to Reporting', font_size=10)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48229759",
   "metadata": {},
   "source": [
    "Temporal Heatmap with Time of Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc1e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('Database/final/crime_data_modified_final.csv')\n",
    "\n",
    "# Convert times to datetime and extract hour and day\n",
    "df['date_occ'] = pd.to_datetime(df['date_occ'])\n",
    "df['date_rept'] = pd.to_datetime(df['date_rept'])\n",
    "df['hour'] = df['date_occ'].dt.hour\n",
    "df['weekday'] = df['date_occ'].dt.day_name()\n",
    "\n",
    "# Calculate the delay in hours\n",
    "df['delay_hours'] = (df['date_rept'] - df['date_occ']).dt.total_seconds() / 3600\n",
    "\n",
    "# Pivot table to organize the data\n",
    "pivot_table = df.pivot_table(values='delay_hours', index='weekday', columns='hour', aggfunc='mean')\n",
    "\n",
    "# Create the heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(pivot_table, cmap='viridis')\n",
    "plt.title('Average Delay in Reporting (Hours) by Time of Day and Day of Week')\n",
    "plt.xlabel('Hour of Day')\n",
    "plt.ylabel('Day of Week')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1899388",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install altair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34f0c1f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
